import streamlit as st
import pandas as pd
import numpy as np
import glob
import os
import json
from datetime import datetime
import altair as alt

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="é›¶å”®æ•°æ®åˆ†æå¹³å°",
    page_icon="ğŸ‘©ğŸ»â€ğŸ’»",
    layout="wide",
    initial_sidebar_state="expanded"
)

# æ•°æ®æ ¹ç›®å½•
DATA_ROOT = "data/"


# åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ•°æ®é›†
def list_datasets():
    """è·å–æ‰€æœ‰å¯ç”¨æ•°æ®é›†"""
    datasets = []
    for name in os.listdir(DATA_ROOT):
        path = os.path.join(DATA_ROOT, name)
        if os.path.isdir(path):
            if glob.glob(os.path.join(path, f"{name}_data_*.csv")):
                datasets.append(name)
    return sorted(datasets)


# ä»ä¾§è¾¹æ è·å–é€‰ä¸­çš„æ•°æ®é›†
def get_selected_dataset():
    """ä»ä¼šè¯çŠ¶æ€è·å–é€‰ä¸­çš„æ•°æ®é›†"""
    datasets = list_datasets()

    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if 'selected_dataset' not in st.session_state:
        st.session_state.selected_dataset = datasets[0] if datasets else None

    # åœ¨ä¾§è¾¹æ æ˜¾ç¤ºæ•°æ®é›†é€‰æ‹©å™¨
    with st.sidebar:
        st.header("ğŸ“ æ•°æ®é›†é€‰æ‹©")
        selected = st.selectbox(
            "é€‰æ‹©æ•°æ®é›†",
            options=datasets,
            index=datasets.index(st.session_state.selected_dataset) if datasets else 0,
            key="dataset_selector"
        )

        if selected != st.session_state.selected_dataset:
            st.session_state.selected_dataset = selected
            # æ¸…é™¤ç¼“å­˜ï¼Œå¼ºåˆ¶é‡æ–°åŠ è½½æ•°æ®
            st.cache_data.clear()

        st.markdown("---")
        st.info(f"å½“å‰åˆ†æ: **{st.session_state.selected_dataset}**")

    return st.session_state.selected_dataset


# å°è£…æ–‡ä»¶å¤„ç†é€»è¾‘ - é€šç”¨ç‰ˆæœ¬
def process_data_files(dataset_name):
    """å¤„ç†æ‰€æœ‰æ•°æ®æ–‡ä»¶å¹¶è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡"""
    dataset_dir = os.path.join(DATA_ROOT, dataset_name)
    files = sorted(glob.glob(os.path.join(dataset_dir, f"{dataset_name}_data_*.csv")))
    stats_files = {
        'category': os.path.join(dataset_dir, f"{dataset_name}_category_stats.jsonl"),
        'null': os.path.join(dataset_dir, f"{dataset_name}_null_stats.jsonl"),
        'unique': os.path.join(dataset_dir, f"{dataset_name}_unique_stats.jsonl")
    }

    # æ£€æŸ¥å·²å¤„ç†çš„æ—¥æœŸ
    processed_dates = {key: set() for key in stats_files}
    for key, file_path in stats_files.items():
        if os.path.exists(file_path):
            with open(file_path, 'r') as f:
                for line in f:
                    data = json.loads(line)
                    processed_dates[key].add(data['date'])

    # å¤„ç†æ–°æ–‡ä»¶
    for file in files:
        try:
            # ä»æ–‡ä»¶åè§£ææ—¥æœŸ
            filename = os.path.basename(file)
            date_str = filename.split('_')[-1].replace('.csv', '')

            # è¯»å–CSV
            df = pd.read_csv(file, dtype=str, keep_default_na=False)

            # åˆ†ç±»ç»Ÿè®¡
            if date_str not in processed_dates['category']:
                count_df = df.groupby(['department', 'category', 'subcategory']).size().reset_index(name='count')
                with open(stats_files['category'], 'a') as f:
                    for _, row in count_df.iterrows():
                        record = {
                            'date': date_str,
                            'department': str(row['department']),
                            'category': str(row['category']),
                            'subcategory': str(row['subcategory']),
                            'count': int(row['count'])
                        }
                        f.write(json.dumps(record) + '\n')
                processed_dates['category'].add(date_str)

            # ç©ºå€¼ç»Ÿè®¡
            if date_str not in processed_dates['null']:
                null_counts = {}
                for col in df.columns:
                    null_counts[col] = int((df[col] == '').sum())
                null_counts['date'] = date_str
                with open(stats_files['null'], 'a') as f:
                    f.write(json.dumps(null_counts) + '\n')
                processed_dates['null'].add(date_str)

            # å”¯ä¸€å€¼ç»Ÿè®¡
            if date_str not in processed_dates['unique']:
                unique_counts = {}
                for col in df.columns:
                    # è®¡ç®—éç©ºå”¯ä¸€å€¼æ•°é‡
                    non_empty = df[col][df[col] != '']
                    unique_counts[col] = int(non_empty.nunique())
                unique_counts['date'] = date_str
                with open(stats_files['unique'], 'a') as f:
                    f.write(json.dumps(unique_counts) + '\n')
                processed_dates['unique'].add(date_str)

        except Exception as e:
            st.error(f"å¤„ç†æ–‡ä»¶ {filename} æ—¶å‡ºé”™: {str(e)}")

    # è¿”å›æ‰€æœ‰å¯ç”¨æ—¥æœŸ
    return sorted(processed_dates['category'])


# å°è£…æ•°æ®åŠ è½½é€»è¾‘
@st.cache_data
def load_stat_data(file_name):
    """åŠ è½½ç»Ÿè®¡JSONLæ–‡ä»¶æ•°æ®"""
    if os.path.exists(file_name):
        data = []
        with open(file_name, 'r') as f:
            for line in f:
                data.append(json.loads(line))
        return pd.DataFrame(data)
    return pd.DataFrame()


# åŠ è½½å•æ—¥åŸå§‹æ•°æ®ç”¨äºå¼‚å¸¸æ£€æµ‹ - é€šç”¨ç‰ˆæœ¬
@st.cache_data
def load_daily_data(dataset_name, date_str):
    dataset_dir = os.path.join(DATA_ROOT, dataset_name)
    file = os.path.join(dataset_dir, f"{dataset_name}_data_{date_str}.csv")
    if os.path.exists(file):
        df = pd.read_csv(file, dtype=str, keep_default_na=False)
        # è½¬æ¢ä»·æ ¼åˆ—ä¸ºæ•°å€¼ç±»å‹
        if 'current_price' in df.columns:
            df['current_price'] = pd.to_numeric(df['current_price'], errors='coerce')
        if 'retail_price' in df.columns:
            df['retail_price'] = pd.to_numeric(df['retail_price'], errors='coerce')
        return df
    return pd.DataFrame()


# ä¸»åº”ç”¨å‡½æ•°
def main():
    # è·å–é€‰ä¸­çš„æ•°æ®é›†
    dataset_name = get_selected_dataset()

    if not dataset_name:
        st.warning("æ²¡æœ‰æ‰¾åˆ°å¯ç”¨æ•°æ®é›†ã€‚è¯·ç¡®ä¿åœ¨data/ç›®å½•ä¸‹æœ‰æ•°æ®é›†æ–‡ä»¶å¤¹")
        return

    # è®¾ç½®é¡µé¢æ ‡é¢˜
    st.title(f"ğŸ“Š {dataset_name.capitalize()} äº§å“æ•°æ®åˆ†æ")

    # é¢„è®¡ç®—ç»Ÿè®¡ç»“æœ
    with st.spinner("å¤„ç†æ•°æ®æ–‡ä»¶ä¸­..."):
        available_dates = process_data_files(dataset_name)

    if not available_dates:
        st.warning("æ²¡æœ‰å¯ç”¨çš„æ—¥æœŸæ•°æ®è¿›è¡Œå±•ç¤º")
        return

    # åŠ è½½ç»Ÿè®¡æ•°æ®
    dataset_dir = os.path.join(DATA_ROOT, dataset_name)
    stats_df = load_stat_data(os.path.join(dataset_dir, f"{dataset_name}_category_stats.jsonl"))
    null_stats_df = load_stat_data(os.path.join(dataset_dir, f"{dataset_name}_null_stats.jsonl"))
    unique_stats_df = load_stat_data(os.path.join(dataset_dir, f"{dataset_name}_unique_stats.jsonl"))

    # ====================== ç¬¬ä¸€éƒ¨åˆ†ï¼šæ¦‚è§ˆè¡¨æ ¼å’ŒæŠ˜çº¿å›¾ ======================
    st.header("ğŸ“Š 1. äº§å“åˆ†ç±»æ¦‚è§ˆ")

    if not stats_df.empty:
        # åˆ›å»ºé€è§†è¡¨
        pivot_df = stats_df.pivot_table(
            index=['department', 'category', 'subcategory'],
            columns='date',
            values='count',
            fill_value=0
        ).reset_index()

        # æ·»åŠ å†å²è¶‹åŠ¿åˆ—
        pivot_df['å†å²è¶‹åŠ¿'] = pivot_df[available_dates].apply(
            lambda row: [int(x) for x in row],
            axis=1
        )

        st.subheader("åˆ†ç±»äº§å“æ•°é‡ç»Ÿè®¡")

        # åˆ›å»ºåˆ—é…ç½®
        column_config = {
            "department": "éƒ¨é—¨",
            "category": "ç±»åˆ«",
            "subcategory": "å­åˆ†ç±»",
            "å†å²è¶‹åŠ¿": st.column_config.LineChartColumn(
                "æ•°é‡å˜åŒ–è¶‹åŠ¿",
                help="å„æ—¥æœŸäº§å“æ•°é‡å˜åŒ–",
                width="medium"
            )
        }

        # æ·»åŠ æ—¥æœŸåˆ—çš„é…ç½®
        for date in available_dates:
            if date in pivot_df.columns:
                column_config[date] = st.column_config.NumberColumn(
                    date,
                    format="%dä»¶"
                )

        # æ˜¾ç¤ºè¡¨æ ¼
        st.dataframe(
            pivot_df,
            column_config=column_config,
            hide_index=True,
            use_container_width=True
        )

        # ====================== äº¤äº’å¼æŠ˜çº¿å›¾ ======================
        st.subheader("äº§å“æ•°é‡å˜åŒ–è¶‹åŠ¿å›¾")

        # å‡†å¤‡ç»˜å›¾æ•°æ®
        trend_data = stats_df.copy()
        trend_data['æ—¥æœŸ'] = pd.to_datetime(trend_data['date'])

        # åˆ›å»ºå¤šçº§é€‰æ‹©å™¨
        col1, col2, col3 = st.columns(3)

        with col1:
            departments = st.multiselect(
                "é€‰æ‹©éƒ¨é—¨",
                options=trend_data['department'].unique(),
                default=trend_data['department'].unique()[0] if len(trend_data['department'].unique()) > 0 else []
            )

        with col2:
            if departments:
                categories_options = trend_data[trend_data['department'].isin(departments)]['category'].unique()
            else:
                categories_options = trend_data['category'].unique()

            categories = st.multiselect(
                "é€‰æ‹©ç±»åˆ«",
                options=categories_options,
                default=categories_options[0] if len(categories_options) > 0 else []
            )

        with col3:
            if departments and categories:
                subcategories_options = trend_data[
                    (trend_data['department'].isin(departments)) &
                    (trend_data['category'].isin(categories))
                    ]['subcategory'].unique()
            elif departments:
                subcategories_options = trend_data[trend_data['department'].isin(departments)]['subcategory'].unique()
            elif categories:
                subcategories_options = trend_data[trend_data['category'].isin(categories)]['subcategory'].unique()
            else:
                subcategories_options = trend_data['subcategory'].unique()

            subcategories = st.multiselect(
                "é€‰æ‹©å­åˆ†ç±»",
                options=subcategories_options,
                default=subcategories_options[:min(3, len(subcategories_options))] if len(
                    subcategories_options) > 0 else []
            )

        # ç­›é€‰æ•°æ®
        filtered_data = trend_data.copy()
        if departments:
            filtered_data = filtered_data[filtered_data['department'].isin(departments)]
        if categories:
            filtered_data = filtered_data[filtered_data['category'].isin(categories)]
        if subcategories:
            filtered_data = filtered_data[filtered_data['subcategory'].isin(subcategories)]

        # äº¤äº’å¼æŠ˜çº¿å›¾
        if not filtered_data.empty:
            # è®¡ç®—Yè½´èŒƒå›´
            y_min_val = filtered_data['count'].min()
            y_max_val = filtered_data['count'].max()
            range_buffer = max(1, (y_max_val - y_min_val) * 0.1) if y_max_val != y_min_val else 1
            y_min_val = max(0, y_min_val - range_buffer)
            y_max_val += range_buffer

            chart = alt.Chart(filtered_data).mark_line(point=True).encode(
                x=alt.X('æ—¥æœŸ:T', title='æ—¥æœŸ'),
                y=alt.Y('count:Q', title='äº§å“æ•°é‡', scale=alt.Scale(domain=[y_min_val, y_max_val])),
                color=alt.Color('subcategory:N', legend=alt.Legend(title="å­åˆ†ç±»")),
                tooltip=[
                    alt.Tooltip('department:N', title='éƒ¨é—¨'),
                    alt.Tooltip('category:N', title='ç±»åˆ«'),
                    alt.Tooltip('subcategory:N', title='å­åˆ†ç±»'),
                    alt.Tooltip('æ—¥æœŸ:T', title='æ—¥æœŸ', format='%Y-%m-%d'),
                    alt.Tooltip('count:Q', title='æ•°é‡', format='.0f')
                ]
            ).properties(
                height=500,
                title='äº§å“æ•°é‡éšæ—¶é—´å˜åŒ–è¶‹åŠ¿'
            ).interactive()

            st.altair_chart(chart, use_container_width=True)
        else:
            st.info("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªåˆ†ç±»è¿›è¡Œå¯è§†åŒ–")
    else:
        st.warning("æ²¡æœ‰å¯ç”¨çš„ç»Ÿè®¡æ•°æ®è¿›è¡Œå±•ç¤º")

    # ====================== ç¬¬äºŒéƒ¨åˆ†ï¼šè¯¦ç»†è¡¨æ ¼ä¸æ—¥æœŸç­›é€‰ ======================
    st.header("ğŸ“… 2. è¯¦ç»†åˆ†ç±»æ•°æ®")

    if not stats_df.empty:
        # æ—¥æœŸé€‰æ‹©æ»‘å—
        selected_date = st.select_slider("é€‰æ‹©æŸ¥çœ‹æ—¥æœŸ", options=available_dates)

        # ç­›é€‰æ•°æ®
        detailed_df = stats_df[stats_df['date'] == selected_date]
        detailed_df = detailed_df.sort_values('count', ascending=False)

        st.subheader(f"{selected_date} äº§å“åˆ†ç±»ç»Ÿè®¡")

        # åˆ›å»ºåˆ—é…ç½®
        max_value = int(detailed_df['count'].max()) if not detailed_df.empty else 1
        detailed_config = {
            "department": "éƒ¨é—¨",
            "category": "ç±»åˆ«",
            "subcategory": "å­åˆ†ç±»",
            "count": st.column_config.ProgressColumn(
                "äº§å“æ•°é‡",
                help="è¯¥å­åˆ†ç±»çš„äº§å“æ•°é‡",
                format="%d",
                min_value=0,
                max_value=max_value
            )
        }

        st.dataframe(
            detailed_df[['department', 'category', 'subcategory', 'count']],
            column_config=detailed_config,
            hide_index=True,
            use_container_width=True
        )
    else:
        st.warning("æ²¡æœ‰å¯ç”¨çš„ç»Ÿè®¡æ•°æ®è¿›è¡Œå±•ç¤º")

    # ====================== ç¬¬ä¸‰éƒ¨åˆ†ï¼šå¼‚å¸¸ä»·æ ¼æ£€æµ‹ ======================
    st.header("âš ï¸ 3. å¼‚å¸¸ä»·æ ¼æ£€æµ‹")

    if not available_dates:
        st.warning("æ²¡æœ‰å¯ç”¨çš„æ•°æ®è¿›è¡Œå¼‚å¸¸æ£€æµ‹")
    else:
        # é€‰æ‹©æ—¥æœŸè¿›è¡Œå¼‚å¸¸æ£€æµ‹
        anomaly_date = st.selectbox("é€‰æ‹©æ£€æµ‹æ—¥æœŸ", options=available_dates, index=len(available_dates) - 1)
        daily_df = load_daily_data(dataset_name, anomaly_date)

        if daily_df.empty:
            st.warning(f"æ²¡æœ‰æ‰¾åˆ° {anomaly_date} çš„æ•°æ®")
        else:
            # è‡ªå®šä¹‰é˜ˆå€¼è¾“å…¥
            st.subheader("è®¾ç½®å¼‚å¸¸ä»·æ ¼é˜ˆå€¼")
            col1, col2 = st.columns(2)

            with col1:
                low_threshold_percent = st.number_input(
                    "ä»·æ ¼è¿‡ä½é˜ˆå€¼ï¼ˆç›¸å¯¹äºä¸­ä½æ•°çš„ç™¾åˆ†æ¯”ï¼‰",
                    min_value=0.1, max_value=100.0, value=20.0, step=0.1,
                    help="ä¾‹å¦‚ï¼šè¾“å…¥20è¡¨ç¤ºä»·æ ¼ä½äºä¸­ä½æ•°çš„20%è¢«è§†ä¸ºå¼‚å¸¸"
                )

            with col2:
                high_threshold_multiple = st.number_input(
                    "ä»·æ ¼è¿‡é«˜é˜ˆå€¼ï¼ˆç›¸å¯¹äºä¸­ä½æ•°çš„å€æ•°ï¼‰",
                    min_value=1.0, max_value=100.0, value=5.0, step=0.1,
                    help="ä¾‹å¦‚ï¼šè¾“å…¥5è¡¨ç¤ºä»·æ ¼é«˜äºä¸­ä½æ•°çš„5å€è¢«è§†ä¸ºå¼‚å¸¸"
                )

            # æ˜¾ç¤ºå¼‚å¸¸å€¼æ£€æµ‹æ ‡å‡†
            st.subheader("å¼‚å¸¸å€¼æ£€æµ‹æ ‡å‡†")
            st.write(f"""
            æˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹æ ‡å‡†æ£€æµ‹å¼‚å¸¸ä»·æ ¼ï¼š
            - **ç¼ºå¤±å€¼**ï¼šä»·æ ¼æ•°æ®ä¸ºç©º
            - **éæ­£å€¼**ï¼šä»·æ ¼ â‰¤ 0
            - **ä»·æ ¼è¿‡ä½**ï¼šä»·æ ¼ < ä¸­ä½æ•°çš„{low_threshold_percent}%
            - **ä»·æ ¼è¿‡é«˜**ï¼šä»·æ ¼ > ä¸­ä½æ•°çš„{high_threshold_multiple}å€
            """)

            # æ£€æµ‹å¼‚å¸¸ä»·æ ¼å‡½æ•°
            def detect_price_anomalies(price_series, low_threshold_percent, high_threshold_multiple):
                anomalies = pd.Series(False, index=price_series.index)
                too_low = pd.Series(False, index=price_series.index)
                too_high = pd.Series(False, index=price_series.index)

                median_price = price_series.median()

                # æ£€æµ‹ç¼ºå¤±å€¼
                missing = price_series.isna()

                # æ£€æµ‹é›¶/è´Ÿå€¼
                non_positive = price_series <= 0

                # æ£€æµ‹è¿‡ä½ä»·æ ¼
                if median_price > 0:
                    low_threshold = median_price * (low_threshold_percent / 100)
                    too_low = (price_series < low_threshold) & (price_series > 0)
                else:
                    too_low = pd.Series(False, index=price_series.index)

                # æ£€æµ‹è¿‡é«˜ä»·æ ¼
                if median_price > 0:
                    high_threshold = median_price * high_threshold_multiple
                    too_high = price_series > high_threshold
                else:
                    too_high = pd.Series(False, index=price_series.index)

                # ç»„åˆæ‰€æœ‰å¼‚å¸¸æ¡ä»¶
                anomalies = missing | non_positive | too_low | too_high

                return anomalies, too_low, too_high, median_price

            # è¯†åˆ«å¼‚å¸¸å€¼
            current_median = retail_median = None
            current_anomalies = retail_anomalies = pd.Series(False)

            if 'current_price' in daily_df.columns:
                (current_anomalies, current_too_low, current_too_high, current_median) = detect_price_anomalies(
                    daily_df['current_price'], low_threshold_percent, high_threshold_multiple
                )
                daily_df['current_price_anomaly'] = current_anomalies

            if 'retail_price' in daily_df.columns:
                (retail_anomalies, retail_too_low, retail_too_high, retail_median) = detect_price_anomalies(
                    daily_df['retail_price'], low_threshold_percent, high_threshold_multiple
                )
                daily_df['retail_price_anomaly'] = retail_anomalies

            # è·å–å¼‚å¸¸æ•°æ®
            price_columns = [c for c in ['current_price_anomaly', 'retail_price_anomaly'] if c in daily_df.columns]

            if not price_columns:
                st.warning("æ•°æ®é›†ä¸­æ²¡æœ‰æ‰¾åˆ°ä»·æ ¼åˆ—")
                return

            anomaly_condition = daily_df[price_columns[0]]
            for col in price_columns[1:]:
                anomaly_condition = anomaly_condition | daily_df[col]

            price_anomalies = daily_df[anomaly_condition]

            # æ˜¾ç¤ºå¼‚å¸¸å€¼ç»Ÿè®¡
            st.subheader("å¼‚å¸¸ä»·æ ¼ç»Ÿè®¡")
            col1, col2 = st.columns(2)

            with col1:
                if current_median is not None:
                    st.metric("å½“å‰ä»·æ ¼ä¸­ä½æ•°", f"${current_median:.2f}" if pd.notna(current_median) else "N/A")
                    st.metric("å½“å‰ä»·æ ¼å¼‚å¸¸æ€»æ•°", f"{current_anomalies.sum()}æ¡")
                    st.metric("å½“å‰ä»·æ ¼ç¼ºå¤±", f"{daily_df['current_price'].isna().sum()}æ¡")
                    st.metric("å½“å‰ä»·æ ¼éæ­£", f"{(daily_df['current_price'] <= 0).sum()}æ¡")
                    if 'current_too_low' in locals():
                        st.metric("å½“å‰ä»·æ ¼è¿‡ä½", f"{current_too_low.sum()}æ¡")
                else:
                    st.info("æ²¡æœ‰å½“å‰ä»·æ ¼æ•°æ®")

            with col2:
                if retail_median is not None:
                    st.metric("é›¶å”®ä»·æ ¼ä¸­ä½æ•°", f"${retail_median:.2f}" if pd.notna(retail_median) else "N/A")
                    st.metric("é›¶å”®ä»·æ ¼å¼‚å¸¸æ€»æ•°", f"{retail_anomalies.sum()}æ¡")
                    st.metric("é›¶å”®ä»·æ ¼ç¼ºå¤±", f"{daily_df['retail_price'].isna().sum()}æ¡")
                    st.metric("é›¶å”®ä»·æ ¼éæ­£", f"{(daily_df['retail_price'] <= 0).sum()}æ¡")
                    if 'retail_too_high' in locals():
                        st.metric("é›¶å”®ä»·æ ¼è¿‡é«˜", f"{retail_too_high.sum()}æ¡")
                else:
                    st.info("æ²¡æœ‰é›¶å”®ä»·æ ¼æ•°æ®")

            # æ˜¾ç¤ºå¼‚å¸¸æ•°æ®è¡¨æ ¼
            st.subheader("å¼‚å¸¸ä»·æ ¼è®°å½•")

            if not price_anomalies.empty:
                # æ·»åŠ å¼‚å¸¸ç±»å‹åˆ—
                price_anomalies['å¼‚å¸¸ç±»å‹'] = ""

                # å½“å‰ä»·æ ¼å¼‚å¸¸
                if 'current_price' in daily_df.columns:
                    price_anomalies.loc[price_anomalies['current_price'].isna(), 'å¼‚å¸¸ç±»å‹'] += "å½“å‰ä»·æ ¼ç¼ºå¤±; "
                    price_anomalies.loc[price_anomalies['current_price'] <= 0, 'å¼‚å¸¸ç±»å‹'] += "å½“å‰ä»·æ ¼éæ­£; "
                    if 'current_too_low' in locals():
                        price_anomalies.loc[current_too_low[price_anomalies.index], 'å¼‚å¸¸ç±»å‹'] += "å½“å‰ä»·æ ¼è¿‡ä½; "
                    if 'current_too_high' in locals():
                        price_anomalies.loc[current_too_high[price_anomalies.index], 'å¼‚å¸¸ç±»å‹'] += "å½“å‰ä»·æ ¼è¿‡é«˜; "

                # é›¶å”®ä»·æ ¼å¼‚å¸¸
                if 'retail_price' in daily_df.columns:
                    price_anomalies.loc[price_anomalies['retail_price'].isna(), 'å¼‚å¸¸ç±»å‹'] += "é›¶å”®ä»·æ ¼ç¼ºå¤±; "
                    price_anomalies.loc[price_anomalies['retail_price'] <= 0, 'å¼‚å¸¸ç±»å‹'] += "é›¶å”®ä»·æ ¼éæ­£; "
                    if 'retail_too_low' in locals():
                        price_anomalies.loc[retail_too_low[price_anomalies.index], 'å¼‚å¸¸ç±»å‹'] += "é›¶å”®ä»·æ ¼è¿‡ä½; "
                    if 'retail_too_high' in locals():
                        price_anomalies.loc[retail_too_high[price_anomalies.index], 'å¼‚å¸¸ç±»å‹'] += "é›¶å”®ä»·æ ¼è¿‡é«˜; "

                # æ·»åŠ ä»·æ ¼æ¯”è¾ƒåˆ—
                def format_price_comparison(row):
                    parts = []
                    if 'current_price' in row and pd.notna(row['current_price']):
                        parts.append(f"å½“å‰ä»·: ${row['current_price']:.2f}")
                    if 'retail_price' in row and pd.notna(row['retail_price']):
                        parts.append(f"é›¶å”®ä»·: ${row['retail_price']:.2f}")
                    return " | ".join(parts) if parts else "ä»·æ ¼æ•°æ®ä¸å®Œæ•´"

                price_anomalies['ä»·æ ¼æ¯”è¾ƒ'] = price_anomalies.apply(format_price_comparison, axis=1)

                # åˆ›å»ºåˆ—é…ç½® - æ ¹æ®æ•°æ®é›†è°ƒæ•´æ˜¾ç¤ºçš„åˆ—
                display_columns = ['product_name', 'ä»·æ ¼æ¯”è¾ƒ', 'å¼‚å¸¸ç±»å‹', 'product_url']
                anomaly_config = {
                    "product_name": "äº§å“åç§°",
                    "ä»·æ ¼æ¯”è¾ƒ": st.column_config.TextColumn("ä»·æ ¼æ¯”è¾ƒ"),
                    "å¼‚å¸¸ç±»å‹": "å¼‚å¸¸ç±»å‹",
                    "product_url": st.column_config.LinkColumn("äº§å“é“¾æ¥")
                }

                if 'brand' in daily_df.columns:
                    display_columns.insert(1, 'brand')
                    anomaly_config['brand'] = "å“ç‰Œ"
                if 'department' in daily_df.columns:
                    display_columns.insert(1, 'department')
                    anomaly_config['department'] = "éƒ¨é—¨"

                st.dataframe(
                    price_anomalies[display_columns],
                    column_config=anomaly_config,
                    hide_index=True,
                    use_container_width=True
                )
            else:
                st.success("ğŸ‰ æœªæ£€æµ‹åˆ°å¼‚å¸¸ä»·æ ¼è®°å½•")

    # ====================== ç¬¬å››éƒ¨åˆ†ï¼šç©ºå€¼ç»Ÿè®¡æ¿å— ======================
    st.header("ğŸ“‰ 4. æ•°æ®è´¨é‡åˆ†æ - ç©ºå€¼ç»Ÿè®¡")

    if not null_stats_df.empty:
        st.subheader("å„æ—¥æœŸæ–‡ä»¶ä¸­çš„ç©ºå€¼æ•°é‡")

        # ç¡®ä¿æ—¥æœŸæ˜¯å­—ç¬¦ä¸²ç±»å‹
        null_stats_df['date'] = null_stats_df['date'].astype(str)

        # é€‰æ‹©è¦å±•ç¤ºçš„åˆ— (æ’é™¤æ—¥æœŸåˆ—)
        columns_to_show = [col for col in null_stats_df.columns if col != 'date' and not col.startswith('Unnamed')]

        # åˆ›å»ºåˆ—é…ç½®
        null_column_config = {
            "date": st.column_config.TextColumn("æ—¥æœŸ")
        }

        # ä¸ºæ¯åˆ—æ·»åŠ é…ç½®
        for col in columns_to_show:
            null_column_config[col] = st.column_config.NumberColumn(
                col,
                help=f"{col}åˆ—çš„ç©ºå€¼æ•°é‡",
                format="%d"
            )

        # æ˜¾ç¤ºè¡¨æ ¼
        st.dataframe(
            null_stats_df[['date'] + columns_to_show],
            column_config=null_column_config,
            hide_index=True,
            use_container_width=True
        )

        # ç©ºå€¼å˜åŒ–è¶‹åŠ¿å›¾
        st.subheader("ç©ºå€¼æ•°é‡å˜åŒ–è¶‹åŠ¿")

        # å‡†å¤‡ç»˜å›¾æ•°æ®
        null_trend_data = null_stats_df.melt(
            id_vars=['date'],
            value_vars=columns_to_show,
            var_name='column',
            value_name='null_count'
        )

        # è½¬æ¢ä¸ºæ—¥æœŸæ ¼å¼
        null_trend_data['date'] = pd.to_datetime(null_trend_data['date'])

        # é€‰æ‹©è¦å±•ç¤ºçš„åˆ—
        selected_columns = st.multiselect(
            "é€‰æ‹©è¦åˆ†æçš„åˆ— (ç©ºå€¼)",
            options=columns_to_show,
            default=columns_to_show[:min(5, len(columns_to_show))]
        )

        if selected_columns:
            filtered_null_data = null_trend_data[null_trend_data['column'].isin(selected_columns)]

            # åˆ›å»ºæŠ˜çº¿å›¾
            chart = alt.Chart(filtered_null_data).mark_line(point=True).encode(
                x=alt.X('date:T', title='æ—¥æœŸ'),
                y=alt.Y('null_count:Q', title='ç©ºå€¼æ•°é‡'),
                color=alt.Color('column:N', legend=alt.Legend(title="åˆ—å")),
                tooltip=[
                    alt.Tooltip('date:T', title='æ—¥æœŸ', format='%Y-%m-%d'),
                    alt.Tooltip('column:N', title='åˆ—å'),
                    alt.Tooltip('null_count:Q', title='ç©ºå€¼æ•°é‡')
                ]
            ).properties(
                height=400,
                title='å„åˆ—ç©ºå€¼æ•°é‡éšæ—¶é—´å˜åŒ–'
            ).interactive()

            st.altair_chart(chart, use_container_width=True)
        else:
            st.info("è¯·è‡³å°‘é€‰æ‹©ä¸€åˆ—è¿›è¡Œå¯è§†åŒ–")
    else:
        st.warning("æ²¡æœ‰å¯ç”¨çš„ç©ºå€¼ç»Ÿè®¡æ•°æ®")

    # ====================== ç¬¬äº”éƒ¨åˆ†ï¼šå”¯ä¸€å€¼ç»Ÿè®¡æ¿å— ======================
    st.header("ğŸ” 5. æ•°æ®è´¨é‡åˆ†æ - å”¯ä¸€å€¼ç»Ÿè®¡")

    if not unique_stats_df.empty:
        st.subheader("å„æ—¥æœŸæ–‡ä»¶ä¸­çš„å”¯ä¸€å€¼æ•°é‡")

        # ç¡®ä¿æ—¥æœŸæ˜¯å­—ç¬¦ä¸²ç±»å‹
        unique_stats_df['date'] = unique_stats_df['date'].astype(str)

        # é€‰æ‹©è¦å±•ç¤ºçš„åˆ— (æ’é™¤æ—¥æœŸåˆ—)
        columns_to_show = [col for col in unique_stats_df.columns if col != 'date' and not col.startswith('Unnamed')]

        # åˆ›å»ºåˆ—é…ç½®
        unique_column_config = {
            "date": st.column_config.TextColumn("æ—¥æœŸ")
        }

        # ä¸ºæ¯åˆ—æ·»åŠ é…ç½®
        for col in columns_to_show:
            unique_column_config[col] = st.column_config.NumberColumn(
                col,
                help=f"{col}åˆ—çš„å”¯ä¸€å€¼æ•°é‡",
                format="%d"
            )

        # æ˜¾ç¤ºè¡¨æ ¼
        st.dataframe(
            unique_stats_df[['date'] + columns_to_show],
            column_config=unique_column_config,
            hide_index=True,
            use_container_width=True
        )

        # å”¯ä¸€å€¼å˜åŒ–è¶‹åŠ¿å›¾
        st.subheader("å”¯ä¸€å€¼æ•°é‡å˜åŒ–è¶‹åŠ¿")

        # å‡†å¤‡ç»˜å›¾æ•°æ®
        unique_trend_data = unique_stats_df.melt(
            id_vars=['date'],
            value_vars=columns_to_show,
            var_name='column',
            value_name='unique_count'
        )

        # è½¬æ¢ä¸ºæ—¥æœŸæ ¼å¼
        unique_trend_data['date'] = pd.to_datetime(unique_trend_data['date'])

        # é€‰æ‹©è¦å±•ç¤ºçš„åˆ—
        selected_columns = st.multiselect(
            "é€‰æ‹©è¦åˆ†æçš„åˆ— (å”¯ä¸€å€¼)",
            options=columns_to_show,
            default=columns_to_show[:min(5, len(columns_to_show))]
        )

        if selected_columns:
            filtered_unique_data = unique_trend_data[unique_trend_data['column'].isin(selected_columns)]

            # åˆ›å»ºæŠ˜çº¿å›¾
            chart = alt.Chart(filtered_unique_data).mark_line(point=True).encode(
                x=alt.X('date:T', title='æ—¥æœŸ'),
                y=alt.Y('unique_count:Q', title='å”¯ä¸€å€¼æ•°é‡'),
                color=alt.Color('column:N', legend=alt.Legend(title="åˆ—å")),
                tooltip=[
                    alt.Tooltip('date:T', title='æ—¥æœŸ', format='%Y-%m-%d'),
                    alt.Tooltip('column:N', title='åˆ—å'),
                    alt.Tooltip('unique_count:Q', title='å”¯ä¸€å€¼æ•°é‡')
                ]
            ).properties(
                height=400,
                title='å„åˆ—å”¯ä¸€å€¼æ•°é‡éšæ—¶é—´å˜åŒ–'
            ).interactive()

            st.altair_chart(chart, use_container_width=True)
        else:
            st.info("è¯·è‡³å°‘é€‰æ‹©ä¸€åˆ—è¿›è¡Œå¯è§†åŒ–")
    else:
        st.warning("æ²¡æœ‰å¯ç”¨çš„å”¯ä¸€å€¼ç»Ÿè®¡æ•°æ®")


# è¿è¡Œåº”ç”¨
if __name__ == "__main__":
    main()